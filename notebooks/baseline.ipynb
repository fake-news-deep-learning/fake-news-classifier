{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MC934-Baseline.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOQW7UyLOEwZCtJkskwO4Uh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ZPg-p0q8GFPG","executionInfo":{"status":"ok","timestamp":1607896525593,"user_tz":180,"elapsed":998,"user":{"displayName":"Guilherme Perrotta","photoUrl":"","userId":"05974350203989748599"}}},"source":["GLOVE = '/content/gdrive/MyDrive/MC934/glove/glove.6B.300d.txt'"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FRSe-ycANJ9P","executionInfo":{"status":"ok","timestamp":1607896545743,"user_tz":180,"elapsed":20041,"user":{"displayName":"Guilherme Perrotta","photoUrl":"","userId":"05974350203989748599"}},"outputId":"bc540f32-149b-45a0-cdf8-3afe647b899b"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bFs7tJlTNyKE","executionInfo":{"status":"ok","timestamp":1607896561172,"user_tz":180,"elapsed":11034,"user":{"displayName":"Guilherme Perrotta","photoUrl":"","userId":"05974350203989748599"}},"outputId":"df6011c6-30f1-49ee-ea10-c6fd268bc9f2"},"source":["!git clone https://0ad3bca4dadfa2ed70b15ac7d82e34f0e17b0169@github.com/fake-news-deep-learning/fake-news-classifier.git"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Cloning into 'fake-news-classifier'...\n","remote: Enumerating objects: 99, done.\u001b[K\n","remote: Counting objects: 100% (99/99), done.\u001b[K\n","remote: Compressing objects: 100% (59/59), done.\u001b[K\n","remote: Total 99 (delta 47), reused 86 (delta 37), pack-reused 0\u001b[K\n","Unpacking objects: 100% (99/99), done.\n","Checking out files: 100% (16/16), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cyrxMPovOIJP","executionInfo":{"status":"ok","timestamp":1607896647288,"user_tz":180,"elapsed":1510,"user":{"displayName":"Guilherme Perrotta","photoUrl":"","userId":"05974350203989748599"}},"outputId":"9baacf76-82fe-4e2c-bbe9-10e6be05ce43"},"source":["%cd /content/fake-news-classifier\n","!git checkout train\n","%cd src/"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/content/fake-news-classifier\n","Branch 'train' set up to track remote branch 'train' from 'origin'.\n","Switched to a new branch 'train'\n","/content/fake-news-classifier/src\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8yVWv8XyP_M4","executionInfo":{"status":"ok","timestamp":1607896690692,"user_tz":180,"elapsed":644,"user":{"displayName":"Guilherme Perrotta","photoUrl":"","userId":"05974350203989748599"}}},"source":["import train"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FzJphG7LQZaD","executionInfo":{"status":"ok","timestamp":1607900737754,"user_tz":180,"elapsed":4041574,"user":{"displayName":"Guilherme Perrotta","photoUrl":"","userId":"05974350203989748599"}},"outputId":"2087bdac-e5ad-464a-cedb-2f02260b8e1a"},"source":["model, history = train.train_driver(GLOVE)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["100%|██████████| 828/828 [00:00<00:00, 1132708.32it/s]"],"name":"stderr"},{"output_type":"stream","text":["Fitting Tokenizer to dataset.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["removing to from vocab\n","removing and from vocab\n","removing of from vocab\n","removing a from vocab\n","removing that from vocab\n","removing in from vocab\n","removing is from vocab\n","removing i from vocab\n","removing we from vocab\n","removing for from vocab\n","removing you from vocab\n","removing it from vocab\n","removing have from vocab\n","removing this from vocab\n","removing on from vocab\n","removing are from vocab\n","removing be from vocab\n","removing with from vocab\n","removing not from vocab\n","removing as from vocab\n","removing but from vocab\n","removing was from vocab\n","removing they from vocab\n","removing our from vocab\n","removing what from vocab\n","removing he from vocab\n","removing about from vocab\n","removing at from vocab\n","removing do from vocab\n","removing so from vocab\n","removing people from vocab\n","removing will from vocab\n","removing by from vocab\n","removing going from vocab\n","removing from from vocab\n","removing has from vocab\n","removing who from vocab\n","removing all from vocab\n","removing think from vocab\n","removing or from vocab\n","removing if from vocab\n","removing president from vocab\n","Mapping vocabulary with size 6699 to sequences\n","Parsing GLOVE\n"],"name":"stdout"},{"output_type":"stream","text":["400000it [00:34, 11628.97it/s]\n","100%|██████████| 6699/6699 [00:00<00:00, 417461.18it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["word2vec embeds have len 300\n","Translating vocabulary\n","Could not find 226 words in GLOVE.\n","Converting text from train set to sequences.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 565/565 [00:00<00:00, 4337.27it/s]\n","100%|██████████| 98/98 [00:00<00:00, 4462.32it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Converting text from valid set to sequences.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_kernel_1_layer (Conv2 (None, 70, 300, 36)       10836     \n","_________________________________________________________________\n","conv2d_kernel_2_layer (Conv2 (None, 70, 300, 36)       777636    \n","_________________________________________________________________\n","conv2d_kernel_3_layer (Conv2 (None, 70, 300, 36)       1166436   \n","_________________________________________________________________\n","conv2d_kernel_5_layer (Conv2 (None, 70, 300, 36)       1944036   \n","_________________________________________________________________\n","dropout_layer (Dropout)      (None, 70, 300, 36)       0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 756000)            0         \n","_________________________________________________________________\n","linear_layer (Dense)         (None, 1)                 756001    \n","=================================================================\n","Total params: 4,654,945\n","Trainable params: 4,654,945\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/20\n"," 1/19 [>.............................] - ETA: 0s - loss: 0.6903 - binary_accuracy: 0.5312 - true_positives: 11.0000 - true_negatives: 6.0000 - false_positives: 10.0000 - false_negatives: 5.0000WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n","Instructions for updating:\n","use `tf.profiler.experimental.stop` instead.\n","19/19 [==============================] - ETA: 0s - loss: 1416.4438 - binary_accuracy: 0.5049 - true_positives: 146.0000 - true_negatives: 161.0000 - false_positives: 143.0000 - false_negatives: 158.0000 \n","Epoch 00001: saving model to checkpoints/model.01-503.69.h5\n","19/19 [==============================] - 218s 11s/step - loss: 1416.4438 - binary_accuracy: 0.5049 - true_positives: 146.0000 - true_negatives: 161.0000 - false_positives: 143.0000 - false_negatives: 158.0000 - val_loss: 503.6941 - val_binary_accuracy: 0.5102 - val_true_positives: 48.0000 - val_true_negatives: 2.0000 - val_false_positives: 45.0000 - val_false_negatives: 3.0000\n","Epoch 2/20\n","19/19 [==============================] - ETA: 0s - loss: 698.0874 - binary_accuracy: 0.4951 - true_positives: 155.0000 - true_negatives: 146.0000 - false_positives: 158.0000 - false_negatives: 149.0000 \n","Epoch 00002: saving model to checkpoints/model.02-153.26.h5\n","19/19 [==============================] - 216s 11s/step - loss: 698.0874 - binary_accuracy: 0.4951 - true_positives: 155.0000 - true_negatives: 146.0000 - false_positives: 158.0000 - false_negatives: 149.0000 - val_loss: 153.2648 - val_binary_accuracy: 0.5204 - val_true_positives: 50.0000 - val_true_negatives: 1.0000 - val_false_positives: 46.0000 - val_false_negatives: 1.0000\n","Epoch 3/20\n","19/19 [==============================] - ETA: 0s - loss: 56.6344 - binary_accuracy: 0.5099 - true_positives: 166.0000 - true_negatives: 144.0000 - false_positives: 160.0000 - false_negatives: 138.0000 \n","Epoch 00003: saving model to checkpoints/model.03-13.01.h5\n","19/19 [==============================] - 218s 11s/step - loss: 56.6344 - binary_accuracy: 0.5099 - true_positives: 166.0000 - true_negatives: 144.0000 - false_positives: 160.0000 - false_negatives: 138.0000 - val_loss: 13.0102 - val_binary_accuracy: 0.5102 - val_true_positives: 37.0000 - val_true_negatives: 13.0000 - val_false_positives: 34.0000 - val_false_negatives: 14.0000\n","Epoch 4/20\n","19/19 [==============================] - ETA: 0s - loss: 9.6975 - binary_accuracy: 0.5526 - true_positives: 134.0000 - true_negatives: 202.0000 - false_positives: 102.0000 - false_negatives: 170.0000  \n","Epoch 00004: saving model to checkpoints/model.04-4.14.h5\n","19/19 [==============================] - 222s 12s/step - loss: 9.6975 - binary_accuracy: 0.5526 - true_positives: 134.0000 - true_negatives: 202.0000 - false_positives: 102.0000 - false_negatives: 170.0000 - val_loss: 4.1359 - val_binary_accuracy: 0.6122 - val_true_positives: 19.0000 - val_true_negatives: 41.0000 - val_false_positives: 6.0000 - val_false_negatives: 32.0000\n","Epoch 5/20\n","19/19 [==============================] - ETA: 0s - loss: 1.3932 - binary_accuracy: 0.6990 - true_positives: 216.0000 - true_negatives: 209.0000 - false_positives: 95.0000 - false_negatives: 88.0000 \n","Epoch 00005: saving model to checkpoints/model.05-1.45.h5\n","19/19 [==============================] - 223s 12s/step - loss: 1.3932 - binary_accuracy: 0.6990 - true_positives: 216.0000 - true_negatives: 209.0000 - false_positives: 95.0000 - false_negatives: 88.0000 - val_loss: 1.4494 - val_binary_accuracy: 0.6531 - val_true_positives: 32.0000 - val_true_negatives: 32.0000 - val_false_positives: 15.0000 - val_false_negatives: 19.0000\n","Epoch 6/20\n","19/19 [==============================] - ETA: 0s - loss: 0.7034 - binary_accuracy: 0.7763 - true_positives: 243.0000 - true_negatives: 229.0000 - false_positives: 75.0000 - false_negatives: 61.0000 \n","Epoch 00006: saving model to checkpoints/model.06-1.10.h5\n","19/19 [==============================] - 223s 12s/step - loss: 0.7034 - binary_accuracy: 0.7763 - true_positives: 243.0000 - true_negatives: 229.0000 - false_positives: 75.0000 - false_negatives: 61.0000 - val_loss: 1.0953 - val_binary_accuracy: 0.6531 - val_true_positives: 28.0000 - val_true_negatives: 36.0000 - val_false_positives: 11.0000 - val_false_negatives: 23.0000\n","Epoch 7/20\n","19/19 [==============================] - ETA: 0s - loss: 0.4868 - binary_accuracy: 0.8141 - true_positives: 257.0000 - true_negatives: 238.0000 - false_positives: 66.0000 - false_negatives: 47.0000 \n","Epoch 00007: saving model to checkpoints/model.07-0.95.h5\n","19/19 [==============================] - 224s 12s/step - loss: 0.4868 - binary_accuracy: 0.8141 - true_positives: 257.0000 - true_negatives: 238.0000 - false_positives: 66.0000 - false_negatives: 47.0000 - val_loss: 0.9524 - val_binary_accuracy: 0.6939 - val_true_positives: 39.0000 - val_true_negatives: 29.0000 - val_false_positives: 18.0000 - val_false_negatives: 12.0000\n","Epoch 8/20\n","19/19 [==============================] - ETA: 0s - loss: 0.4005 - binary_accuracy: 0.8289 - true_positives: 261.0000 - true_negatives: 243.0000 - false_positives: 61.0000 - false_negatives: 43.0000 \n","Epoch 00008: saving model to checkpoints/model.08-0.93.h5\n","19/19 [==============================] - 224s 12s/step - loss: 0.4005 - binary_accuracy: 0.8289 - true_positives: 261.0000 - true_negatives: 243.0000 - false_positives: 61.0000 - false_negatives: 43.0000 - val_loss: 0.9261 - val_binary_accuracy: 0.6837 - val_true_positives: 32.0000 - val_true_negatives: 35.0000 - val_false_positives: 12.0000 - val_false_negatives: 19.0000\n","Epoch 9/20\n","19/19 [==============================] - ETA: 0s - loss: 0.3753 - binary_accuracy: 0.8322 - true_positives: 265.0000 - true_negatives: 241.0000 - false_positives: 63.0000 - false_negatives: 39.0000 \n","Epoch 00009: saving model to checkpoints/model.09-1.07.h5\n","19/19 [==============================] - 223s 12s/step - loss: 0.3753 - binary_accuracy: 0.8322 - true_positives: 265.0000 - true_negatives: 241.0000 - false_positives: 63.0000 - false_negatives: 39.0000 - val_loss: 1.0667 - val_binary_accuracy: 0.6327 - val_true_positives: 22.0000 - val_true_negatives: 40.0000 - val_false_positives: 7.0000 - val_false_negatives: 29.0000\n","Epoch 10/20\n","19/19 [==============================] - ETA: 0s - loss: 0.3200 - binary_accuracy: 0.8684 - true_positives: 271.0000 - true_negatives: 257.0000 - false_positives: 47.0000 - false_negatives: 33.0000 \n","Epoch 00010: saving model to checkpoints/model.10-1.06.h5\n","19/19 [==============================] - 223s 12s/step - loss: 0.3200 - binary_accuracy: 0.8684 - true_positives: 271.0000 - true_negatives: 257.0000 - false_positives: 47.0000 - false_negatives: 33.0000 - val_loss: 1.0592 - val_binary_accuracy: 0.6327 - val_true_positives: 22.0000 - val_true_negatives: 40.0000 - val_false_positives: 7.0000 - val_false_negatives: 29.0000\n","Epoch 11/20\n","19/19 [==============================] - ETA: 0s - loss: 0.2821 - binary_accuracy: 0.8701 - true_positives: 272.0000 - true_negatives: 257.0000 - false_positives: 47.0000 - false_negatives: 32.0000 \n","Epoch 00011: saving model to checkpoints/model.11-0.90.h5\n","19/19 [==============================] - 223s 12s/step - loss: 0.2821 - binary_accuracy: 0.8701 - true_positives: 272.0000 - true_negatives: 257.0000 - false_positives: 47.0000 - false_negatives: 32.0000 - val_loss: 0.9007 - val_binary_accuracy: 0.6939 - val_true_positives: 35.0000 - val_true_negatives: 33.0000 - val_false_positives: 14.0000 - val_false_negatives: 16.0000\n","Epoch 12/20\n","19/19 [==============================] - ETA: 0s - loss: 0.2426 - binary_accuracy: 0.9062 - true_positives: 283.0000 - true_negatives: 268.0000 - false_positives: 36.0000 - false_negatives: 21.0000 \n","Epoch 00012: saving model to checkpoints/model.12-0.87.h5\n","19/19 [==============================] - 223s 12s/step - loss: 0.2426 - binary_accuracy: 0.9062 - true_positives: 283.0000 - true_negatives: 268.0000 - false_positives: 36.0000 - false_negatives: 21.0000 - val_loss: 0.8738 - val_binary_accuracy: 0.7041 - val_true_positives: 40.0000 - val_true_negatives: 29.0000 - val_false_positives: 18.0000 - val_false_negatives: 11.0000\n","Epoch 13/20\n","19/19 [==============================] - ETA: 0s - loss: 0.2232 - binary_accuracy: 0.9211 - true_positives: 290.0000 - true_negatives: 270.0000 - false_positives: 34.0000 - false_negatives: 14.0000 \n","Epoch 00013: saving model to checkpoints/model.13-0.90.h5\n","19/19 [==============================] - 223s 12s/step - loss: 0.2232 - binary_accuracy: 0.9211 - true_positives: 290.0000 - true_negatives: 270.0000 - false_positives: 34.0000 - false_negatives: 14.0000 - val_loss: 0.9013 - val_binary_accuracy: 0.6735 - val_true_positives: 32.0000 - val_true_negatives: 34.0000 - val_false_positives: 13.0000 - val_false_negatives: 19.0000\n","Epoch 14/20\n","19/19 [==============================] - ETA: 0s - loss: 0.2292 - binary_accuracy: 0.9095 - true_positives: 285.0000 - true_negatives: 268.0000 - false_positives: 36.0000 - false_negatives: 19.0000 \n","Epoch 00014: saving model to checkpoints/model.14-0.99.h5\n","19/19 [==============================] - 223s 12s/step - loss: 0.2292 - binary_accuracy: 0.9095 - true_positives: 285.0000 - true_negatives: 268.0000 - false_positives: 36.0000 - false_negatives: 19.0000 - val_loss: 0.9921 - val_binary_accuracy: 0.6837 - val_true_positives: 28.0000 - val_true_negatives: 39.0000 - val_false_positives: 8.0000 - val_false_negatives: 23.0000\n","Epoch 15/20\n","19/19 [==============================] - ETA: 0s - loss: 0.2025 - binary_accuracy: 0.9276 - true_positives: 290.0000 - true_negatives: 274.0000 - false_positives: 30.0000 - false_negatives: 14.0000 \n","Epoch 00015: saving model to checkpoints/model.15-0.97.h5\n","19/19 [==============================] - 223s 12s/step - loss: 0.2025 - binary_accuracy: 0.9276 - true_positives: 290.0000 - true_negatives: 274.0000 - false_positives: 30.0000 - false_negatives: 14.0000 - val_loss: 0.9743 - val_binary_accuracy: 0.6939 - val_true_positives: 29.0000 - val_true_negatives: 39.0000 - val_false_positives: 8.0000 - val_false_negatives: 22.0000\n","Epoch 16/20\n","19/19 [==============================] - ETA: 0s - loss: 0.1916 - binary_accuracy: 0.9424 - true_positives: 290.0000 - true_negatives: 283.0000 - false_positives: 21.0000 - false_negatives: 14.0000 \n","Epoch 00016: saving model to checkpoints/model.16-0.89.h5\n","19/19 [==============================] - 224s 12s/step - loss: 0.1916 - binary_accuracy: 0.9424 - true_positives: 290.0000 - true_negatives: 283.0000 - false_positives: 21.0000 - false_negatives: 14.0000 - val_loss: 0.8936 - val_binary_accuracy: 0.7041 - val_true_positives: 36.0000 - val_true_negatives: 33.0000 - val_false_positives: 14.0000 - val_false_negatives: 15.0000\n","Epoch 17/20\n","19/19 [==============================] - ETA: 0s - loss: 0.1610 - binary_accuracy: 0.9572 - true_positives: 296.0000 - true_negatives: 286.0000 - false_positives: 18.0000 - false_negatives: 8.0000 \n","Epoch 00017: saving model to checkpoints/model.17-0.89.h5\n","\n","Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","19/19 [==============================] - 223s 12s/step - loss: 0.1610 - binary_accuracy: 0.9572 - true_positives: 296.0000 - true_negatives: 286.0000 - false_positives: 18.0000 - false_negatives: 8.0000 - val_loss: 0.8872 - val_binary_accuracy: 0.6939 - val_true_positives: 38.0000 - val_true_negatives: 30.0000 - val_false_positives: 17.0000 - val_false_negatives: 13.0000\n","Epoch 00017: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dFFxEa9bxm8z","executionInfo":{"status":"ok","timestamp":1607901267532,"user_tz":180,"elapsed":558,"user":{"displayName":"Guilherme Perrotta","photoUrl":"","userId":"05974350203989748599"}}},"source":["import json"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ehVFj9oYlWR","executionInfo":{"status":"ok","timestamp":1607901506422,"user_tz":180,"elapsed":659,"user":{"displayName":"Guilherme Perrotta","photoUrl":"","userId":"05974350203989748599"}}},"source":["history_dict = {}\n","\n","for cat, items in history.history.items():\n","    items_ = [str(item) for item in items]\n","    history_dict[cat] = items_"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Uz_eIwQY41k","executionInfo":{"status":"ok","timestamp":1607901952443,"user_tz":180,"elapsed":627,"user":{"displayName":"Guilherme Perrotta","photoUrl":"","userId":"05974350203989748599"}}},"source":["with open('/content/baseline_history.json', 'w') as out_file:\n","  json.dump(history_dict, out_file, indent=4)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fhbca07_ZMXh","executionInfo":{"status":"ok","timestamp":1607901766762,"user_tz":180,"elapsed":1303,"user":{"displayName":"Guilherme Perrotta","photoUrl":"","userId":"05974350203989748599"}},"outputId":"f099b4ae-4dcb-4dcb-b6e4-80f5714a852a"},"source":["model.save('/content/')"],"execution_count":27,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /content/assets\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YeYg1HbJbwHV"},"source":["# Avaliação do modelo no conjunto de teste"]},{"cell_type":"code","metadata":{"id":"K96EWMabeKKA","executionInfo":{"status":"ok","timestamp":1607902939011,"user_tz":180,"elapsed":597,"user":{"displayName":"Guilherme Perrotta","photoUrl":"","userId":"05974350203989748599"}}},"source":["import numpy as np\n","from tqdm import tqdm\n","\n","from word2vec import prepare_tokenizer, text_to_sequence\n","from utils import load_glove"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z1JdPvb6b2kY","executionInfo":{"status":"ok","timestamp":1607902896477,"user_tz":180,"elapsed":784,"user":{"displayName":"Guilherme Perrotta","photoUrl":"","userId":"05974350203989748599"}}},"source":["def eval(model):\n","    tokenizer = prepare_tokenizer()\n","    word2seq = load_glove(tokenizer.word_index, GLOVE)\n","\n","    print(f'Converting text from test set to sequences.')\n","    with open(f'../data/processed/test.json') as input_file:\n","        dataset = json.load(input_file)\n","\n","    test_x = []\n","    test_y = []\n","\n","    for entry in tqdm(dataset.values()):\n","\n","        sequence = text_to_sequence(\n","            entry['text'],\n","            tokenizer.word_index,\n","            word2seq,\n","        )\n","\n","        test_x.append(sequence)\n","        test_y.append(0 if entry['label'] == 'fake' else 1)\n","\n","    test_y = np.asarray(test_y, dtype=np.float32)\n","    test_x = np.asarray(test_x, dtype=np.float32)\n","\n","    results = model.evaluate(test_x, test_y, verbose=1, return_dict=True)\n","\n","    return results"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hKz54bAzct-_","executionInfo":{"status":"ok","timestamp":1607902993661,"user_tz":180,"elapsed":52129,"user":{"displayName":"Guilherme Perrotta","photoUrl":"","userId":"05974350203989748599"}},"outputId":"b6a624a6-57bb-4d5d-8ee3-d890ab0ffd74"},"source":["results = eval(model)"],"execution_count":40,"outputs":[{"output_type":"stream","text":["100%|██████████| 828/828 [00:00<00:00, 339646.33it/s]"],"name":"stderr"},{"output_type":"stream","text":["Fitting Tokenizer to dataset.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","1475it [00:00, 14743.86it/s]"],"name":"stderr"},{"output_type":"stream","text":["removing to from vocab\n","removing and from vocab\n","removing of from vocab\n","removing a from vocab\n","removing that from vocab\n","removing in from vocab\n","removing is from vocab\n","removing i from vocab\n","removing we from vocab\n","removing for from vocab\n","removing you from vocab\n","removing it from vocab\n","removing have from vocab\n","removing this from vocab\n","removing on from vocab\n","removing are from vocab\n","removing be from vocab\n","removing with from vocab\n","removing not from vocab\n","removing as from vocab\n","removing but from vocab\n","removing was from vocab\n","removing they from vocab\n","removing our from vocab\n","removing what from vocab\n","removing he from vocab\n","removing about from vocab\n","removing at from vocab\n","removing do from vocab\n","removing so from vocab\n","removing people from vocab\n","removing will from vocab\n","removing by from vocab\n","removing going from vocab\n","removing from from vocab\n","removing has from vocab\n","removing who from vocab\n","removing all from vocab\n","removing think from vocab\n","removing or from vocab\n","removing if from vocab\n","removing president from vocab\n","Mapping vocabulary with size 6699 to sequences\n","Parsing GLOVE\n"],"name":"stdout"},{"output_type":"stream","text":["400000it [00:27, 14289.00it/s]\n","100%|██████████| 6699/6699 [00:00<00:00, 458692.09it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["word2vec embeds have len 300\n","Translating vocabulary\n","Could not find 226 words in GLOVE.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 167/167 [00:00<00:00, 4629.11it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Converting text from test set to sequences.\n","6/6 [==============================] - 18s 3s/step - loss: 0.6924 - binary_accuracy: 0.7365 - true_positives: 74.0000 - true_negatives: 49.0000 - false_positives: 26.0000 - false_negatives: 18.0000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fD5jWGotei88","executionInfo":{"status":"ok","timestamp":1607903004812,"user_tz":180,"elapsed":595,"user":{"displayName":"Guilherme Perrotta","photoUrl":"","userId":"05974350203989748599"}},"outputId":"1f3a49e9-b4bf-4430-91d7-b8888bebeee3"},"source":["results"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'binary_accuracy': 0.7365269660949707,\n"," 'false_negatives': 18.0,\n"," 'false_positives': 26.0,\n"," 'loss': 0.692355215549469,\n"," 'true_negatives': 49.0,\n"," 'true_positives': 74.0}"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"IqBT34QDfMYA","executionInfo":{"status":"ok","timestamp":1607903088909,"user_tz":180,"elapsed":570,"user":{"displayName":"Guilherme Perrotta","photoUrl":"","userId":"05974350203989748599"}}},"source":["with open('/content/results.json', 'w') as results_file:\n","  json.dump(results, results_file, indent=4)"],"execution_count":42,"outputs":[]}]}
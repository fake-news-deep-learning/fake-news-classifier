{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPg-p0q8GFPG"
      },
      "source": [
        "GLOVE = '/content/gdrive/MyDrive/MC934/glove/glove.42B.300d.txt'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7xGOKPTNfOn"
      },
      "source": [
        "WORDS_PER_EXAMPLE = 210"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRSe-ycANJ9P",
        "outputId": "8abc4972-b2b1-4564-eb29-644a49c8a8f0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFs7tJlTNyKE",
        "outputId": "36e58ee7-6220-4bf1-db3b-c806be9cad15"
      },
      "source": [
        "!git clone https://TOKEN@github.com/fake-news-deep-learning/fake-news-classifier.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fake-news-classifier'...\n",
            "remote: Enumerating objects: 357, done.\u001b[K\n",
            "remote: Counting objects: 100% (357/357), done.\u001b[K\n",
            "remote: Compressing objects: 100% (209/209), done.\u001b[K\n",
            "remote: Total 357 (delta 229), reused 268 (delta 144), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (357/357), 37.53 MiB | 25.08 MiB/s, done.\n",
            "Resolving deltas: 100% (229/229), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyrxMPovOIJP",
        "outputId": "c2a46c8e-e8c8-4653-c4ca-70aa33e2d963"
      },
      "source": [
        "%cd /content/fake-news-classifier\n",
        "!git checkout train_lstm\n",
        "%cd src/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fake-news-classifier\n",
            "Branch 'train_lstm' set up to track remote branch 'train_lstm' from 'origin'.\n",
            "Switched to a new branch 'train_lstm'\n",
            "/content/fake-news-classifier/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YzIMZAiM0RI",
        "outputId": "644e6ac4-6c49-47d6-bc0a-954c93ac4f29"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects:  25% (1/4)   \rUnpacking objects:  50% (2/4)   \rUnpacking objects:  75% (3/4)   \rUnpacking objects: 100% (4/4)   \rUnpacking objects: 100% (4/4), done.\n",
            "From https://github.com/fake-news-deep-learning/fake-news-classifier\n",
            "   ea4fe6b..9c99363  train_lstm -> origin/train_lstm\n",
            "Updating ea4fe6b..9c99363\n",
            "Fast-forward\n",
            " src/train.py | 5 \u001b[32m+++\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 3 insertions(+), 2 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yVWv8XyP_M4"
      },
      "source": [
        "import train"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx6yDKHbR4DN",
        "outputId": "f02e0138-1292-4014-e054-29c2b2c164b9"
      },
      "source": [
        "import importlib\n",
        "importlib.reload(train)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'train' from '/content/fake-news-classifier/src/train.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8iB2kITKmJ2",
        "outputId": "99ee1b0b-3f55-42be-8f18-54e036655b3d"
      },
      "source": [
        "tokenizer, word2veq = train.prepare_data(GLOVE)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 699/699 [00:00<00:00, 321365.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting Tokenizer to dataset.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Corpus has 29903 words.\n",
            "Removed rare words, which were 78.49% of corpus.\n",
            "Succesfully removed 136 stopwords.\n",
            "Mapping vocabulary with size 6296 to sequences\n",
            "Parsing GLOVE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1917494it [02:18, 13803.97it/s]\n",
            "100%|██████████| 6296/6296 [00:00<00:00, 374274.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "word2vec embeds have len 300\n",
            "Translating vocabulary\n",
            "Could not find 173 words in GLOVE.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzJphG7LQZaD",
        "outputId": "2a57ae69-f615-4229-e8f6-fa5994263bd3"
      },
      "source": [
        "model, history = train.lstm_driver(tokenizer, word2veq, epochs=40, length=WORDS_PER_EXAMPLE)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 477/477 [00:00<00:00, 3932.19it/s]\n",
            "100%|██████████| 84/84 [00:00<00:00, 2026.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Converting text from train set to sequences.\n",
            "Converting text from valid set to sequences.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dropout_layer (Dropout)      (None, 210, 300)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 600)               1442400   \n",
            "_________________________________________________________________\n",
            "linear_layer (Dense)         (None, 1)                 601       \n",
            "=================================================================\n",
            "Total params: 1,443,001\n",
            "Trainable params: 1,443,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/40\n",
            "15/15 [==============================] - 5s 124ms/step - loss: 0.6299 - binary_accuracy: 0.6691 - true_positives: 119.6250 - true_negatives: 119.2500 - false_positives: 56.7500 - false_negatives: 58.3750 - val_loss: 0.6052 - val_binary_accuracy: 0.7024 - val_true_positives: 18.0000 - val_true_negatives: 41.0000 - val_false_positives: 0.0000e+00 - val_false_negatives: 25.0000\n",
            "\n",
            "Epoch 00001: saving model to checkpoints/model.01-0.61.h5\n",
            "Epoch 2/40\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 0.3991 - binary_accuracy: 0.8093 - true_positives: 105.0625 - true_negatives: 116.6875 - false_positives: 18.3125 - false_negatives: 29.9375 - val_loss: 0.8503 - val_binary_accuracy: 0.7738 - val_true_positives: 37.0000 - val_true_negatives: 28.0000 - val_false_positives: 13.0000 - val_false_negatives: 6.0000\n",
            "\n",
            "Epoch 00002: saving model to checkpoints/model.02-0.85.h5\n",
            "Epoch 3/40\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 0.4233 - binary_accuracy: 0.8301 - true_positives: 109.4375 - true_negatives: 118.8125 - false_positives: 16.1875 - false_negatives: 25.5625 - val_loss: 0.5261 - val_binary_accuracy: 0.7500 - val_true_positives: 30.0000 - val_true_negatives: 33.0000 - val_false_positives: 8.0000 - val_false_negatives: 13.0000\n",
            "\n",
            "Epoch 00003: saving model to checkpoints/model.03-0.53.h5\n",
            "Epoch 4/40\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.3413 - binary_accuracy: 0.8601 - true_positives: 109.0000 - true_negatives: 122.9375 - false_positives: 12.0625 - false_negatives: 26.0000 - val_loss: 0.5030 - val_binary_accuracy: 0.7262 - val_true_positives: 31.0000 - val_true_negatives: 30.0000 - val_false_positives: 11.0000 - val_false_negatives: 12.0000\n",
            "\n",
            "Epoch 00004: saving model to checkpoints/model.04-0.50.h5\n",
            "Epoch 5/40\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 0.2615 - binary_accuracy: 0.9110 - true_positives: 126.3750 - true_negatives: 119.1250 - false_positives: 15.8750 - false_negatives: 8.6250 - val_loss: 0.5185 - val_binary_accuracy: 0.7857 - val_true_positives: 28.0000 - val_true_negatives: 38.0000 - val_false_positives: 3.0000 - val_false_negatives: 15.0000\n",
            "\n",
            "Epoch 00005: saving model to checkpoints/model.05-0.52.h5\n",
            "Epoch 6/40\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 0.1898 - binary_accuracy: 0.9258 - true_positives: 124.6250 - true_negatives: 125.6875 - false_positives: 9.3125 - false_negatives: 10.3750 - val_loss: 0.5930 - val_binary_accuracy: 0.7262 - val_true_positives: 23.0000 - val_true_negatives: 38.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
            "\n",
            "Epoch 00006: saving model to checkpoints/model.06-0.59.h5\n",
            "Epoch 7/40\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 0.2046 - binary_accuracy: 0.9126 - true_positives: 125.1875 - true_negatives: 121.9375 - false_positives: 13.0625 - false_negatives: 9.8125 - val_loss: 0.5079 - val_binary_accuracy: 0.7262 - val_true_positives: 24.0000 - val_true_negatives: 37.0000 - val_false_positives: 4.0000 - val_false_negatives: 19.0000\n",
            "\n",
            "Epoch 00007: saving model to checkpoints/model.07-0.51.h5\n",
            "Epoch 8/40\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 0.1483 - binary_accuracy: 0.9608 - true_positives: 128.3750 - true_negatives: 129.1250 - false_positives: 5.8750 - false_negatives: 6.6250 - val_loss: 0.6274 - val_binary_accuracy: 0.7262 - val_true_positives: 23.0000 - val_true_negatives: 38.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
            "\n",
            "Epoch 00008: saving model to checkpoints/model.08-0.63.h5\n",
            "Epoch 9/40\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 0.1128 - binary_accuracy: 0.9689 - true_positives: 130.9375 - true_negatives: 129.8125 - false_positives: 5.1875 - false_negatives: 4.0625 - val_loss: 0.4510 - val_binary_accuracy: 0.8214 - val_true_positives: 30.0000 - val_true_negatives: 39.0000 - val_false_positives: 2.0000 - val_false_negatives: 13.0000\n",
            "\n",
            "Epoch 00009: saving model to checkpoints/model.09-0.45.h5\n",
            "Epoch 10/40\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 0.1175 - binary_accuracy: 0.9639 - true_positives: 130.5625 - true_negatives: 129.8750 - false_positives: 5.1250 - false_negatives: 4.4375 - val_loss: 0.5537 - val_binary_accuracy: 0.7143 - val_true_positives: 31.0000 - val_true_negatives: 29.0000 - val_false_positives: 12.0000 - val_false_negatives: 12.0000\n",
            "\n",
            "Epoch 00010: saving model to checkpoints/model.10-0.55.h5\n",
            "Epoch 11/40\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 0.0846 - binary_accuracy: 0.9791 - true_positives: 132.9375 - true_negatives: 130.8750 - false_positives: 4.1250 - false_negatives: 2.0625 - val_loss: 0.8166 - val_binary_accuracy: 0.7381 - val_true_positives: 23.0000 - val_true_negatives: 39.0000 - val_false_positives: 2.0000 - val_false_negatives: 20.0000\n",
            "\n",
            "Epoch 00011: saving model to checkpoints/model.11-0.82.h5\n",
            "Epoch 12/40\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 0.0598 - binary_accuracy: 0.9871 - true_positives: 132.7500 - true_negatives: 132.2500 - false_positives: 2.7500 - false_negatives: 2.2500 - val_loss: 0.4836 - val_binary_accuracy: 0.7738 - val_true_positives: 34.0000 - val_true_negatives: 31.0000 - val_false_positives: 10.0000 - val_false_negatives: 9.0000\n",
            "\n",
            "Epoch 00012: saving model to checkpoints/model.12-0.48.h5\n",
            "Epoch 13/40\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 0.0632 - binary_accuracy: 0.9820 - true_positives: 133.1250 - true_negatives: 131.8125 - false_positives: 3.1875 - false_negatives: 1.8750 - val_loss: 0.6525 - val_binary_accuracy: 0.7262 - val_true_positives: 27.0000 - val_true_negatives: 34.0000 - val_false_positives: 7.0000 - val_false_negatives: 16.0000\n",
            "\n",
            "Epoch 00013: saving model to checkpoints/model.13-0.65.h5\n",
            "Epoch 14/40\n",
            "15/15 [==============================] - 1s 37ms/step - loss: 0.0437 - binary_accuracy: 0.9931 - true_positives: 133.9375 - true_negatives: 133.7500 - false_positives: 1.2500 - false_negatives: 1.0625 - val_loss: 0.6114 - val_binary_accuracy: 0.8095 - val_true_positives: 35.0000 - val_true_negatives: 33.0000 - val_false_positives: 8.0000 - val_false_negatives: 8.0000\n",
            "\n",
            "Epoch 00014: saving model to checkpoints/model.14-0.61.h5\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 00014: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFFxEa9bxm8z"
      },
      "source": [
        "import json"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ehVFj9oYlWR"
      },
      "source": [
        "history_dict = {}\n",
        "\n",
        "for cat, items in history.history.items():\n",
        "    items_ = [str(item) for item in items]\n",
        "    history_dict[cat] = items_"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Uz_eIwQY41k"
      },
      "source": [
        "with open('/content/baseline_history.json', 'w') as out_file:\n",
        "  json.dump(history_dict, out_file, indent=4)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhbca07_ZMXh",
        "outputId": "e5335c8d-2058-4ad6-b29b-35222dc68604"
      },
      "source": [
        "model.save('/content/')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_17_layer_call_fn, lstm_cell_17_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_17_layer_call_fn, lstm_cell_17_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeYg1HbJbwHV"
      },
      "source": [
        "# Avaliação do modelo no conjunto de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K96EWMabeKKA"
      },
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from word2vec import prepare_tokenizer, text_to_sequence\n",
        "from utils import load_glove"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1JdPvb6b2kY"
      },
      "source": [
        "def eval(model, tokenizer, word2seq):\n",
        "\n",
        "    print(f'Converting text from test set to sequences.')\n",
        "    with open(f'../data/processed/test.json') as input_file:\n",
        "        dataset = json.load(input_file)\n",
        "\n",
        "    test_x = []\n",
        "    test_y = []\n",
        "\n",
        "    for entry in tqdm(dataset.values()):\n",
        "\n",
        "        sequence = text_to_sequence(\n",
        "            entry['text'],\n",
        "            tokenizer.word_index,\n",
        "            word2seq,\n",
        "            length=WORDS_PER_EXAMPLE,\n",
        "            mode='lstm'\n",
        "        )\n",
        "\n",
        "        test_x.append(sequence)\n",
        "        test_y.append(0 if entry['label'] == 'fake' else 1)\n",
        "\n",
        "    test_y = np.asarray(test_y, dtype=np.float32)\n",
        "    test_x = np.asarray(test_x, dtype=np.float32)\n",
        "\n",
        "    results = model.evaluate(test_x, test_y, verbose=1, return_dict=True)\n",
        "\n",
        "    return results"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKz54bAzct-_",
        "outputId": "a48b60bd-e8ed-4da3-e263-8b8d934b8d47"
      },
      "source": [
        "results = eval(model, tokenizer, word2veq)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 140/140 [00:00<00:00, 1520.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Converting text from test set to sequences.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5006 - binary_accuracy: 0.8643 - true_positives: 63.0000 - true_negatives: 58.0000 - false_positives: 7.0000 - false_negatives: 12.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD5jWGotei88",
        "outputId": "5b1393ce-db20-4b5e-9bc4-d05b735fb295"
      },
      "source": [
        "results"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'binary_accuracy': 0.8642857074737549,\n",
              " 'false_negatives': 12.0,\n",
              " 'false_positives': 7.0,\n",
              " 'loss': 0.5005921721458435,\n",
              " 'true_negatives': 58.0,\n",
              " 'true_positives': 63.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqBT34QDfMYA"
      },
      "source": [
        "with open('/content/results.json', 'w') as results_file:\n",
        "  json.dump(results, results_file, indent=4)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2cNE4I8L0ZQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}